{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dea81b3-c6bb-42a1-9708-dd8363b68186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brevitas version: 0.10.3\n",
      "Input tensor:\n",
      "tensor([[0.1538, 0.2910]])\n",
      "\n",
      "Model output (before int conversion):\n",
      "tensor([[-0.0076, -0.0328]])\n",
      "\n",
      "Model output (after int32 conversion):\n",
      "tensor([[-2147483648, -2147483648]], dtype=torch.int32)\n",
      "\n",
      "Model output (after int64 conversion):\n",
      "tensor([[ -50867355648, -221071736832]])\n",
      "\n",
      "Software-only output:\n",
      "[[ -50867339837 -221071725940]]\n",
      "\n",
      "Difference between int64 Brevitas and software-only:\n",
      "[[-15811 -10892]]\n",
      "Max absolute difference (int64): 15811\n",
      "\n",
      "Difference between int32 Brevitas and software-only:\n",
      "[[ 48719856189 218924242292]]\n",
      "Max absolute difference (int32): 218924242292\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from brevitas.nn import QuantIdentity, QuantLinear, QuantReLU\n",
    "from brevitas.quant import Int8WeightPerTensorFloat, Int8Bias\n",
    "from brevitas.quant_tensor import QuantTensor\n",
    "import brevitas\n",
    "\n",
    "# Print Brevitas version\n",
    "print(f\"Brevitas version: {brevitas.__version__}\")\n",
    "\n",
    "# Constants\n",
    "N_INPUT = 2\n",
    "N_HIDDEN_1 = 64\n",
    "N_HIDDEN_2 = 80\n",
    "SCALE = 1/32000.\n",
    "\n",
    "def quantize_input_tensor(in_float, scale, bit_width=16, zero_point=0.0, training=False, device=torch.device('cpu')):\n",
    "    int_value = in_float / scale\n",
    "    quant_value = (int_value - zero_point) * scale\n",
    "    quant_tensor_input = QuantTensor(\n",
    "        quant_value,\n",
    "        scale=torch.tensor(scale),\n",
    "        zero_point=torch.tensor(zero_point),\n",
    "        bit_width=torch.tensor(float(bit_width)),\n",
    "        signed=True,\n",
    "        training=training).to(device)\n",
    "    return quant_tensor_input\n",
    "\n",
    "class Digital_twin(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, scale, device):\n",
    "        super(Digital_twin, self).__init__()\n",
    "        self.fc1 = QuantLinear(obs_dim, hidden_sizes[0], bias=True, \n",
    "                               weight_quant=Int8WeightPerTensorFloat, bias_quant=Int8Bias, return_quant_tensor=True)\n",
    "        self.fc1.cache_inference_quant_bias=True\n",
    "        self.relu1 = QuantReLU(act_quant=None, return_quant_tensor=True)\n",
    "        self.fc2 = QuantLinear(hidden_sizes[0], hidden_sizes[1], bias=True, \n",
    "                               weight_quant=Int8WeightPerTensorFloat, bias_quant=Int8Bias, return_quant_tensor=True)\n",
    "        self.fc2.cache_inference_quant_bias=True\n",
    "        self.relu2 = QuantReLU(act_quant=None, return_quant_tensor=True)\n",
    "        self.fc3 = QuantLinear(hidden_sizes[1], 2 * act_dim, bias=True, \n",
    "                               weight_quant=Int8WeightPerTensorFloat, bias_quant=Int8Bias, return_quant_tensor=True)\n",
    "        self.fc3.cache_inference_quant_bias=True\n",
    "        self.device = device\n",
    "        self.scale = scale\n",
    "        \n",
    "    def forward(self, obs):\n",
    "        obs = quantize_input_tensor(obs, self.scale, training=self.training, device=self.device)\n",
    "        net_out = self.fc1(obs)\n",
    "        net_out = self.relu1(net_out)\n",
    "        net_out = self.fc2(net_out)\n",
    "        net_out = self.relu2(net_out)\n",
    "        net_out = self.fc3(net_out)\n",
    "        return net_out\n",
    "\n",
    "def create_input_tensor(dim, scale, device):\n",
    "    random_numbers = np.random.uniform(low=10., high=16000., size=(1, dim)).astype(np.int16)    \n",
    "    tensor = torch.tensor(random_numbers, dtype=torch.float32, device=device)\n",
    "    return tensor * scale\n",
    "\n",
    "# Software-only forward pass\n",
    "def software_forward(X, W1, b1, W2, b2, W3, b3):\n",
    "    def relu(x):\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    A1 = relu(np.dot(W1, X.T) + b1)\n",
    "    A2 = relu(np.dot(W2, A1) + b2)\n",
    "    Y = np.dot(W3, A2) + b3\n",
    "    return Y.T\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cpu')\n",
    "    hidden_sizes = [N_HIDDEN_1, N_HIDDEN_2]\n",
    "    model = Digital_twin(N_INPUT, 1, hidden_sizes, SCALE, device).to(device)\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Create input tensor\n",
    "    in_float = create_input_tensor(N_INPUT, SCALE, device)\n",
    "    \n",
    "    print(\"Input tensor:\")\n",
    "    print(in_float)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        out_brevitas = model(in_float)\n",
    "    \n",
    "    print(\"\\nModel output (before int conversion):\")\n",
    "    print(out_brevitas.value)\n",
    "    \n",
    "    # Int32 conversion (will overflow)\n",
    "    out_brevitas_int32 = out_brevitas.int()\n",
    "    print(\"\\nModel output (after int32 conversion):\")\n",
    "    print(out_brevitas_int32)\n",
    "    \n",
    "    # Int64 conversion\n",
    "    out_brevitas_int64 = (out_brevitas.value / out_brevitas.scale[0,0]).to(torch.int64)\n",
    "    print(\"\\nModel output (after int64 conversion):\")\n",
    "    print(out_brevitas_int64)\n",
    "    \n",
    "    # Software-only forward pass\n",
    "    W1 = model.fc1.quant_weight().int().cpu().numpy().astype(np.int64)\n",
    "    b1 = model.fc1.quant_bias().int().cpu().numpy().astype(np.int64).reshape(-1, 1)\n",
    "    W2 = model.fc2.quant_weight().int().cpu().numpy().astype(np.int64)\n",
    "    b2 = model.fc2.quant_bias().int().cpu().numpy().astype(np.int64).reshape(-1, 1)\n",
    "    W3 = model.fc3.quant_weight().int().cpu().numpy().astype(np.int64)\n",
    "    b3 = model.fc3.quant_bias().int().cpu().numpy().astype(np.int64).reshape(-1, 1)\n",
    "    \n",
    "    X_sw = (in_float / SCALE).cpu().numpy().astype(np.int64)\n",
    "    Y_sw = software_forward(X_sw, W1, b1, W2, b2, W3, b3)\n",
    "    \n",
    "    print(\"\\nSoftware-only output:\")\n",
    "    print(Y_sw)\n",
    "    \n",
    "    # Compare results with int64\n",
    "    print(\"\\nDifference between int64 Brevitas and software-only:\")\n",
    "    diff_int64 = out_brevitas_int64.cpu().numpy() - Y_sw\n",
    "    print(diff_int64)\n",
    "    print(f\"Max absolute difference (int64): {np.abs(diff_int64).max()}\")\n",
    "    \n",
    "    # Compare results with int32\n",
    "    print(\"\\nDifference between int32 Brevitas and software-only:\")\n",
    "    diff_int32 = out_brevitas_int32.cpu().numpy() - Y_sw\n",
    "    print(diff_int32)\n",
    "    print(f\"Max absolute difference (int32): {np.abs(diff_int32).max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27dc9c2-e7c3-4376-924f-161d3105e106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7143d-3f66-4452-a922-5e01bd51c539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
